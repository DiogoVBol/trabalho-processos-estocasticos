---
title: "Random Walk"
output: html_document
date: "2024-11-18"
---

```{r}
library(knitr)

```


1 - a definição do processo estocástico (cadeia de Markov);

Suponha que $U=(U_{1},U_{2},U_{3}...)$ é uma sequência de variáveis aleatória independetes, com valores entre 1 e -1 e probabilidades $p \in[0,1]$ e $1-p$ respectivamente. Seja $X= (X_{0},X_{1},X_{2}...)$ a soma parcial do processo associado a $U$, então:

$$X_{n}=\sum_{i=1}^{n}U_{i}$$

A sequência $X$ é chamada de passeio aleatório simples (ou somente passeio aleatório) com parametro $p$.

Agora suponha que $p=\frac{1}{2}$. Nesse caso, $X=(X_{0},X_{1},X_{2}...)$ é chamado de passeio aleatório simétrico simples (ou passeio simétrico aleatório). Em particular,

$$P(X_{i}=e_{i})=P(X_{i}=-e_{i})=\frac{1}{2d}, i=1,2,3...d.$$

Ou seja, em um passeio aleatório simétrico, o usuário se desloca aleatoriamente um passo por vez, com todas as direções possíveis sendo igualmente prováveis. Por exemplo, em duas dimensões ($d=2$), ele pode ir para cima, baixo, esquerda ou direita, com probabilidade de $\frac{1}{4}$ para cada direção.

- O termo "simétrico" refere-se ao fato de que todas as direções possíveis têm a mesma probabilidade de serem escolhidas.


Fontes:

https://stats.libretexts.org/Bookshelves/Probability_Theory/Probability_Mathematical_Statistics_and_Stochastic_Processes_(Siegrist)/11%3A_Bernoulli_Trials/11.06%3A_The_Simple_Random_Walk

https://math.uchicago.edu/~may/VIGRE/VIGRE2011/REUPapers/Johnston.pdf



2 - a matriz de transição; 

#### Definição de Matriz de Transição

A **matriz de transição** $P$ descreve as probabilidades de transição de um estado $i$ para outro estado $j$ em um único passo.

Para o passeio aleatório com espaço de estados $S= \mathbb{Z}$, temos:

$$ 
P_{i,j} = 
\begin{cases} 
p & \text{se } j = i+1, \\
1-p & \text{se } j = i-1, \\
0 & \text{caso contrário.}
\end{cases}
$$

#### Representação da Matriz $P$

Se $S = \{0, 1, 2 ,3 ,4\}$ um espaço de estados discreto finito, a matriz de transição $P$ é dada por:

$$
P = 
\begin{bmatrix}
P_{0,0} & P_{0,1} & P_{0,2} & P_{0,3} & P_{0,4} \\
P_{1,0} & P_{1,1} & P_{1,2} & P_{1,3} & P_{1,4} \\
P_{2,0} & P_{2,1} & P_{2,2} & P_{2,3} & P_{2,4} \\
P_{3,0} & P_{3,1} & P_{3,2} & P_{3,3} & P_{3,4} \\
P_{4,0} & P_{4,1} & P_{4,2} & P_{4,3} & P_{4,4} 
\end{bmatrix}. 
$$

Para o nosso caso de passeio aleatório **finito** $S =\{0,1,2,...,N\}$ a matriz de transição será uma matriz $(N+1)\times(N+1)$.

Mas também nesse caso precisamos definir umas condições de contorno:
- **Contorno reflexivo**: Se estamos no estado extremo $i=0$ ou $i=N$, o sistema "rebate" e não sai do espaço
- **Contorno absorvente**: O sistema permanece no estado extremo $i=0$ ou $i=N$

Vamos definir o **Contorno Reflexivo** para estudo e apresentação deste trabalho, pois note que definindo o contorno da matriz de transição sofremos alteração no problema todo como um geral e suas distribuições.

$$
P =
\begin{bmatrix}
1-p & p & 0 & \dots & 0 \\
1-p & 0 & p & \dots & 0 \\
0 & 1-p & 0 & \dots & p \\
\vdots & \vdots & \ddots & \ddots & \vdots \\
0 & \dots & 0 & 1-p & p \\
0 & \dots & 0 & 1-p & p
\end{bmatrix}.
$$

*Propriedades da Matriz de Transição*: **Estocasticidade**, **Simetria (para $p=1/2$)**, **Sparsa** (para eu estudar para apresentação)

Como estamos trabalhando com passeio aleatório simétrico, temos $p = \frac{1}{2}$. Temos simetria pois as probabilidades de transição para frente $(i + 1)$ e para trás $(i - 1)$ são iguais!
Consequentemente, temos para assimétrico $p \neq \frac{1}{2}$.

Podemos analisar as matrizes dada a simetria e assímetria associadas e suas propriedades!

#### **4. Exemplo para \( N = 3 \) (espaço \( S = \{0, 1, 2, 3\} \))**
Com \( p = 0.5 \) e contornos reflexivos:
$$
P =
\begin{bmatrix}
0.5 & 0.5 & 0 & 0 \\
0.5 & 0 & 0.5 & 0 \\
0 & 0.5 & 0 & 0.5 \\
0 & 0 & 0.5 & 0.5
\end{bmatrix}.
$$
*Propriedades Específicas*: **Recorrência**, **Distribuição Assintótica**

#### Caso passeio Aleatório Assimétrico $p \neq \frac{1}{2}$
Com \( p = 0.66 \) e contornos reflexivos:
$$
P =
\begin{bmatrix}
0.33 & 0.66 & 0 & 0 \\
0.33 & 0 & 0.66 & 0 \\
0 & 0.33 & 0 & 0.66 \\
0 & 0 & 0.33 & 0.66
\end{bmatrix}.
$$

*Propriedades Específicas*: **Têndencia Direcional**, **Irreversibilidade**

Só para eu salvar aqui xdd
https://stats.libretexts.org/Bookshelves/Probability_Theory/Probability_Mathematical_Statistics_and_Stochastic_Processes_(Siegrist)/11%3A_Bernoulli_Trials/11.06%3A_The_Simple_Random_Walk
https://stats.libretexts.org/Bookshelves/Probability_Theory/Introductory_Probability_(Grinstead_and_Snell)/12%3A_Random_Walks

3 - distibuição invariante e distribuição limite (quando houver);

### Distribuição invariante
A **distribuição invariante** de uma cadeia de Markov como vista em aula é uma distribuição de probabilidade $\pi = (\pi_i)$ tal que, ao aplicarmos a matriz de transição $P$, a distribuição permanece inalterada tal que:
$$
\pi P = \pi.
$$

Em nosso contexto de apresentação (passeio aleatório simétrico), teriamos

- A matriz de transição $P$ é simétrica para $p = \frac{1}{2}$
- Em espaços de estados finitos, a distribuição invariante é uniforme:

$$ \pi_i = \frac{1}{|S|} $$

- para todos os estados $i$, onde $|S|$ é o número total de estados. Isso ocorre porque as transições são igualmente prováveis em todas as direções.

**Para o nosso exemplo de espaço discreto finito $S={0, 1, 2,3}:$**
$$
P = \begin{bmatrix}
0 & \frac{1}{2} & 0 & 0 \\
\frac{1}{2} & 0 & \frac{1}{2} & 0 \\
0 & \frac{1}{2} & 0 & \frac{1}{2} \\
0 & 0 & \frac{1}{2} & 0
\end{bmatrix} \
$$

A distribuição invariante será:

$$
\pi = \left( \frac{1}{4}, \frac{1}{4}, \frac{1}{4}, \frac{1}{4} \right)
$$

### Distribuição Limite
A **distibuição limite** de uma cadeia de Markov é o estado ao qual a distribuição converge  muitas iterações da matriz da transição, isto é, quando $n \to \infty$

$$
\lim_{n \to \infty} P^n(i, j)
$$

Como vimos em aula, um **espaço de estados finitos**, a distribuição limite será igual à distribuição invariante.

Para um **espaço infinito $S= \mathbb{Z}$** o passeio simétrico não converge para uma distribuição estacionária porque o sistema "se espalha" indefinidamente. A probabilidade de estar e um estado específico diminui com o tempo!
Ou seja, se começarmos no ponto 0, após *n* passos, a posição $X_n$ do objeto será distribuída aproximadamente como uma normal com média 0 e variância n
$$
X_n ~ N(0, n)
$$

4 - classificação dos estados e da cadeia;

Por definição um estado $i$ é dito ser **recorrente** se $v_{ii}^*=1$ (a cadeira retorna ao $i$ com probabilidade 1).

O estado $i$ é dito ser transiente se ele não é recorrente.

Portanto, para a matriz de exemplo, considerando $p=\frac{1}{2}$:

$$
P = 
\begin{bmatrix}
0 & 1 & 0 & 0 & 0 \\
\frac{1}{2} & 0 & \frac{1}{2} & 0 & 0 \\
0 & \frac{1}{2} & 0 & \frac{1}{2} & 0 \\
0 & 0 & \frac{1}{2} & 0 & \frac{1}{2} \\
0 & 0 & 0 & 1 & 0
\end{bmatrix}.
$$

<div style="text-align: center;">
```{r, echo=FALSE, out.width="30%"}
include_graphics("img/01.png")
```
</div>

Análisando o grafo podemos notar que os estados {0,1,2,3,4} são uma classe fechada, irredutível.

George Pólya provou o seguinte teorema: 

*"Um passeio aleatório simples em $\mathbb{Z}^D$ é recorrente se e somente se é simétrico e D < 3."*

Então, temos a distribuição estacionária: 

$$
\pi_{i}=\frac{1}{2}\pi_{i-1}+\frac{1}{2}\pi_{i+1}
$$
A soma das probabilidades para deslocamento a esquerda e a direita são iguais, então podemos argumentar que a distribuição estacionária é constante para todos os estados.

Assim temos, para todos os estados $i$:

$$
\pi_{i}=\pi_{0}
$$

Como temos um processo recorrente e com distribuição estacionária $\pi_{i}=\pi_{0}$ concluímos que todos os estados em um processo de caminhada aleatória simétrica de dimensão 2 são recorrentes nulos.

5 - periodicidade;

6 - Tempo de primeira visita/passagem e recorrência

7 - Probabilidade de absorção

8 - Curiosidades e questões interessantes relacionadas ao problema específico.