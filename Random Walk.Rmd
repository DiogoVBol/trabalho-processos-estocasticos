---
title: "Random Walk"
output: html_document
date: "2024-11-18"
---

1 - a definição do processo estocástico (cadeia de Markov);

Suponha que $U=(U_{1},U_{2},U_{3}...)$ é uma sequência de variáveis aleatória independetes, com valores entre 1 e -1 e probabilidades $p \in[0,1]$ e $1-p$ respectivamente. Seja $X= (X_{0},X_{1},X_{2}...)$ a soma parcial do processo associado a $U$, então:

$$X_{n}=\sum_{i=1}^{n}U_{i}$$

A sequência $X$ é chamada de passeio aleatório simples (ou somente passeio aleatório) com parametro $p$.

Agora suponha que $p=\frac{1}{2}$. Nesse caso, $X=(X_{0},X_{1},X_{2}...)$ é chamado de passeio aleatório simétrico simples (ou passeio simétrico aleatório). Em particular,

$$P(X_{i}=e_{i})=P(X_{i}=-e_{i})=\frac{1}{2d}, i=1,2,3...d.$$

Ou seja, em um passeio aleatório simétrico, o usuário se desloca aleatoriamente um passo por vez, com todas as direções possíveis sendo igualmente prováveis. Por exemplo, em duas dimensões ($d=2$), ele pode ir para cima, baixo, esquerda ou direita, com probabilidade de $\frac{1}{4}$ para cada direção.

- O termo "simétrico" refere-se ao fato de que todas as direções possíveis têm a mesma probabilidade de serem escolhidas.


Fontes:

https://stats.libretexts.org/Bookshelves/Probability_Theory/Probability_Mathematical_Statistics_and_Stochastic_Processes_(Siegrist)/11%3A_Bernoulli_Trials/11.06%3A_The_Simple_Random_Walk

https://math.uchicago.edu/~may/VIGRE/VIGRE2011/REUPapers/Johnston.pdf



2 - a matriz de transição; 

#### Definição de Matriz de Transição

A **matriz de transição** $P$ descreve as probabilidades de transição de um estado $i$ para outro estado $j$ em um único passo.

Para o passeio aleatório com espaço de estados $S= \mathbb{Z}$, temos:

$$ 
P_{i,j} = 
\begin{cases} 
p & \text{se } j = i+1, \\
1-p & \text{se } j = i-1, \\
0 & \text{caso contrário.}
\end{cases}
$$

#### Representação da Matriz $P$

Se $S = \{0, 1, 2 ,3 ,4\}$ um espaço de estados discreto finito, a matriz de transição $P$ é dada por:

$$
P = 
\begin{bmatrix}
P_{0,0} & P_{0,1} & P_{0,2} & P_{0,3} & P_{0,4} \\
P_{1,0} & P_{1,1} & P_{1,2} & P_{1,3} & P_{1,4} \\
P_{2,0} & P_{2,1} & P_{2,2} & P_{2,3} & P_{2,4} \\
P_{3,0} & P_{3,1} & P_{3,2} & P_{3,3} & P_{3,4} \\
P_{4,0} & P_{4,1} & P_{4,2} & P_{4,3} & P_{4,4} 
\end{bmatrix}. 
$$

Para o nosso caso de passeio aleatório **finito** $S =\{0,1,2,...,N\}$ a matriz de transição será uma matriz $(N+1)\times(N+1)$.

também precisamos definir umas condições de contorno:

- **Contorno reflexivo**: Se estamos no estado extremo $i=0$ ou $i=N$, o sistema "rebate" e não sai do espaço

$$
P =
\begin{bmatrix}
0.5 & 0.5 & 0 & 0 \\
0.5 & 0 & 0.5 & 0 \\
0 & 0.5 & 0 & 0.5 \\
0 & 0 & 0.5 & 0.5
\end{bmatrix}.
$$

- **Contorno absorvente**: O sistema permanece no estado extremo $i=0$ ou $i=N$

$$
P =
\begin{bmatrix}
1 & 0 & 0 & 0 \\
0.5 & 0 & 0.5 & 0 \\
0 & 0.5 & 0 & 0.5 \\
0 & 0 & 0 & 1
\end{bmatrix}.
$$

Vamos definir o **Contorno Reflexivo** para estudo e apresentação deste trabalho, pois note que definindo o contorno da matriz de transição sofremos alteração no problema todo como um geral e suas distribuições.

$$
P =
\begin{bmatrix}
1-p & p & 0 & \dots & 0 \\
1-p & 0 & p & \dots & 0 \\
0 & 1-p & 0 & \dots & p \\
\vdots & \vdots & \ddots & \ddots & \vdots \\
0 & \dots & 0 & 1-p & p \\
0 & \dots & 0 & 1-p & p
\end{bmatrix}.
$$

*Propriedades da Matriz de Transição*: **Estocasticidade**, **Simetria (para $p=1/2$)**, **Sparsa** (para eu estudar para apresentação)

Como estamos trabalhando com passeio aleatório simétrico, temos $p = \frac{1}{2}$. Temos simetria pois as probabilidades de transição para frente $(i + 1)$ e para trás $(i - 1)$ são iguais!
Consequentemente, temos para assimétrico $p \neq \frac{1}{2}$.

Podemos analisar as matrizes dada a simetria e assímetria associadas e suas propriedades!

#### **4. Exemplo para \( N = 3 \) (espaço \( S = \{0, 1, 2, 3\} \))**
Com \( p = 0.5 \) e contornos reflexivos:
$$
P =
\begin{bmatrix}
0.5 & 0.5 & 0 & 0 \\
0.5 & 0 & 0.5 & 0 \\
0 & 0.5 & 0 & 0.5 \\
0 & 0 & 0.5 & 0.5
\end{bmatrix}.
$$
*Propriedades Específicas*: **Recorrência**, **Distribuição Assintótica**

#### Caso passeio Aleatório Assimétrico $p \neq \frac{1}{2}$
Com \( p = 0.66 \) e contornos reflexivos:
$$
P =
\begin{bmatrix}
0.33 & 0.66 & 0 & 0 \\
0.33 & 0 & 0.66 & 0 \\
0 & 0.33 & 0 & 0.66 \\
0 & 0 & 0.33 & 0.66
\end{bmatrix}.
$$
*Propriedades Específicas*: **Têndencia Direcional**, **Irreversibilidade**

### Exemplos de transição a **n** passos:

É interessante observar o comportamento da matriz de transição para um número grande de passos. Vamos considerar o caso de  $N = 3$  e  $p = 0.5$  e calcular a matriz de transição para $n = 2$ e $n = 3$, $n=4$ e $n=500$.

Matriz $P^2$ (transição em 2 passos):

$$
P^2 =
\begin{bmatrix}
0.5 & 0.25 & 0.25 & 0 \\
0.25 & 0.5 & 0 & 0.25 \\
0.25 & 0 & 0.5 & 0.25 \\
0 & 0.25 & 0.25 & 0.5
\end{bmatrix}.
$$

O que podemos observar aqui?

- As probabilidades de transição são mais equilibradas em relação à matriz original $P$, pois a random walk ja teve chance de "se mover" por mais de um passo.
- Apesar de se espalhar o sistema ainda não atingiu uma distribuição homogênea. A cadeia ainda possui alguma "memória" do estado inicial.
- O sistema começa a ter uma chance maior de ir para estados não-adjacentes, mas ainda há certa "preferência" por estados adjacentes.

Matriz $P^3$ (transição em 3 passos):

$$
P^3 =
\begin{bmatrix}
0.375 & 0.375 & 0.125 & 0.125 \\
0.375 & 0.125 & 0.375 & 0.125 \\
0.125 & 0.375 & 0.125 & 0.375 \\
0.125 & 0.125 & 0.375 & 0.375
\end{bmatrix}.
$$

O que podemos observar aqui?

- As probabilidades estão mais equilibradas entre os estados.
- Apesar de ainda não ser completamente uniforme, da para notar uma maior "mistura" entre os estados.
- O sistema está começando a perder memória do seu estado inicial, a cadeia está mais "descentralizada" e as probabilidades começam a se espalhar mais uniformemente.

Matriz $P^4$ (transição em 4 passos):

$$
P^4 =
\begin{bmatrix}
0.375 & 0.25 & 0.25 & 0.125 \\
0.25 & 0.375 & 0.125 & 0.25 \\
0.25 & 0.125 & 0.375 & 0.25 \\
0.125 & 0.25 & 0.25 & 0.375
\end{bmatrix}.
$$

O que podemos observar aqui?

- Após 4 passos, as probabilidades de transição entre os estados estão quase equilibradas, com uma leve tendência para os estados vizinhos
- O sistema parece estar alcançando um comportamento de **distribuição estacionárioa** (ou próxima disso pelo menos)
- Esse é um comportamento típico de uma cadeia de Markov que está perdendo sua "memória" do estado inicial e se aproximando de uma distribuição a longo prazo

Matriz $P^{500}$ (transição em 500 passos):

$$
P^{500} =
\begin{bmatrix}
0.25 & 0.25 & 0.25 & 0.25 \\
0.25 & 0.25 & 0.25 & 0.25 \\
0.25 & 0.25 & 0.25 & 0.25 \\
0.25 & 0.25 & 0.25 & 0.25
\end{bmatrix}.
$$


O que podemos observar aqui?

- A matriz $P^{500}$ nos mostra que, após um grande número de passos as probabilidades de transição entre os estados estão completamente equilibradas e uniformes
- Cada estado tem uma probabilidade de transitar para qualquer outro estado. Portanto depois de muitos passos a cadeia de Markov perde sua memória do estado inicial e atinge um estado de **equilíbrio estacionário**
- Essa distribuição uniforme de probabilidades é característica de uma cadeia de Markov irreducível e aperiódica, onde todos os estados são acessíveis e a cadeia não possui ciclos regulares.
  

3 - distibuição invariante e distribuição limite (quando houver);

#### Distribuição invariante
A **distribuição invariante** de uma cadeia de Markov como vista em aula é uma distribuição de probabilidade $\pi = (\pi_i)$ tal que, ao aplicarmos a matriz de transição $P$, a distribuição permanece inalterada tal que:
$$
\pi P = \pi.
$$

Em nosso contexto de apresentação (passeio aleatório simétrico *reflexivo*) a "particula" pode explorar todo o espaço $S = \{0,1,...,N\}$ de forma contínuam retornando os estados após atingir os extremos.

Nesse caso então a distribuição invariante neste caso será **uniforme** (pois note que o passeio é simétrico).

Se $\pi = [\pi_0, \pi_1, \dots, \pi_N]$ representa a distribuição invariante:

então

$$
\pi_i = \frac{1}{N+1}, \quad \forall i \in \{0, 1, \dots, N\}.
$$

Note que a distribuição reflete o fato de que ao longo prazo todos os estados têm a mesma probabilidade de serem visitados.

**Para o nosso exemplo de espaço discreto finito $S={0, 1, 2,3}:$**
$$
P = \begin{bmatrix}
\frac{1}{2} & \frac{1}{2} & 0 & 0 \\
\frac{1}{2} & 0 & \frac{1}{2} & 0 \\
0 & \frac{1}{2} & 0 & \frac{1}{2} \\
0 & 0 & \frac{1}{2} & \frac{1}{2}
\end{bmatrix} \
$$

A distribuição invariante será:

$$
\pi = \left( \frac{1}{4}, \frac{1}{4}, \frac{1}{4}, \frac{1}{4} \right)
$$

*Ao longo prazo a partícula estará em qualquer estado com a mesma probabilidade*

#### Distribuição Limite
A **distibuição limite** de uma cadeia de Markov é o estado ao qual a distribuição converge  muitas iterações da matriz da transição, isto é, quando $n \to \infty$ independente da distribuição inicial $\pi^{(0)}$

$$
\lim_{n \to \infty} P^n(i, j)
$$

Como vimos em aula, um **espaço de estados finitos**, a distribuição limite será igual à distribuição invariante.

Para um **espaço infinito $S= \mathbb{Z}$** o passeio simétrico não converge para uma distribuição estacionária porque o sistema "se espalha" indefinidamente. A probabilidade de estar e um estado específico diminui com o tempo!
Ou seja, se começarmos no ponto 0, após *n* passos, a posição $X_n$ do objeto será distribuída aproximadamente como uma normal com média 0 e variância n
$$
X_n ~ N(0, n)
$$

4 - classificação dos estados e da cadeia;

5 - periodicidade;

6 - Tempo de primeira visita/passagem e recorrência

7 - Probabilidade de absorção

8 - Curiosidades e questões interessantes relacionadas ao problema específico.