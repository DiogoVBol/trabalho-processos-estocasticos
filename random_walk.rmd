---
title: "Passeio Aleatório Simétrico"
author: "Davi, Diogo, João e Thiago"
date: "`r Sys.Date()`"

---

```{r setup, echo=FALSE}

knitr::opts_chunk$set(warning = FALSE)

library(knitr)
library(ggplot2)
```

## Definição do processo estocástico (cadeia de Markov);

Suponha que $U=(U_{1},U_{2},U_{3}...)$ é uma sequência de variáveis aleatória independetes, com valores entre 1 e -1 e probabilidades $p \in[0,1]$ e $1-p$ respectivamente. Seja $X= (X_{0},X_{1},X_{2}...)$ a soma parcial do processo associado a $U$, então:

$$X_{n}=\sum_{i=1}^{n}U_{i}$$

A sequência $X$ é chamada de passeio aleatório simples (ou somente passeio aleatório) com parametro $p$.

Agora suponha que $p=\frac{1}{2}$. Nesse caso, $X=(X_{0},X_{1},X_{2}...)$ é chamado de passeio aleatório simétrico simples (ou passeio simétrico aleatório). Em particular,

$$P(X_{i}=e_{i})=P(X_{i}=-e_{i})=\frac{1}{2d}, i=1,2,3...d.$$

Ou seja, em um passeio aleatório simétrico, o usuário se desloca aleatoriamente um passo por vez, com todas as direções possíveis sendo igualmente prováveis. Por exemplo, em duas dimensões ($d=2$), ele pode ir para cima, baixo, esquerda ou direita, com probabilidade de $\frac{1}{4}$ para cada direção.

#### Esperança

Como $X_{n}$ é a soma de variáveis aleatórias $U_{i}$, a esperança de $X_{n}$ pode ser obtida:
$$
\mathbb{E}[X_{n}]=\mathbb{E}[\sum_{i=1}^{n}U_{i}]=\sum_{i=1}^{n}\mathbb{E}[U_{i}]
$$
Como $U_{i}$ assume +1 e -1 ambos com probabilidade $\frac{1}{2}$, temos:
$$
\mathbb{E}[U_{i}]=1\times\frac{1}{2}+(-1)\times\frac{1}{2}=0
$$
Portanto a esperança de $X_{n}$ é igual a zero.

Isso significa que, em média, o processo não tende para um lado específico, mas está igualmente "distribuído" ao redor da origem.

## Matriz de transição;

#### Definição de Matriz de Transição
    
A **matriz de transição** $P$ descreve as probabilidades de transição de um estado $i$ para outro estado $j$ em um único passo.

Para o passeio aleatório com espaço de estados $S= \mathbb{Z}$, temos:

$$ 
P_{i,j} = 
\begin{cases} 
p & \text{se } j = i+1, \\
1-p & \text{se } j = i-1, \\
0 & \text{caso contrário.}
\end{cases}
$$

#### Representação da Matriz $P$

Se $S = \{0, 1, 2 ,3 ,4\}$ um espaço de estados discreto finito, a matriz de transição $P$ é dada por:

$$
P = 
\begin{bmatrix}
P_{0,0} & P_{0,1} & P_{0,2} & P_{0,3} & P_{0,4} \\
P_{1,0} & P_{1,1} & P_{1,2} & P_{1,3} & P_{1,4} \\
P_{2,0} & P_{2,1} & P_{2,2} & P_{2,3} & P_{2,4} \\
P_{3,0} & P_{3,1} & P_{3,2} & P_{3,3} & P_{3,4} \\
P_{4,0} & P_{4,1} & P_{4,2} & P_{4,3} & P_{4,4} 
\end{bmatrix}. 
$$

Para o nosso caso de passeio aleatório **finito** $S =\{0,1,2,...,N\}$ a matriz de transição será uma matriz $(N+1)\times(N+1)$.

também precisamos definir umas condições de contorno:

- **Contorno reflexivo**: Se estamos no estado extremo $i=0$ ou $i=N$, o sistema "rebate" e não sai do espaço

$$
P =
\begin{bmatrix}
0.5 & 0.5 & 0 & 0 \\
0.5 & 0 & 0.5 & 0 \\
0 & 0.5 & 0 & 0.5 \\
0 & 0 & 0.5 & 0.5
\end{bmatrix}.
$$

- **Contorno absorvente**: O sistema permanece no estado extremo $i=0$ ou $i=N$

$$
P =
\begin{bmatrix}
1 & 0 & 0 & 0 \\
0.5 & 0 & 0.5 & 0 \\
0 & 0.5 & 0 & 0.5 \\
0 & 0 & 0 & 1
\end{bmatrix}.
$$

Vamos definir o **Contorno Reflexivo** para estudo e apresentação deste trabalho, pois note que definindo o contorno da matriz de transição sofremos alteração no problema todo como um geral e suas distribuições.

$$
P =
\begin{bmatrix}
1-p & p & 0 & \dots & 0 \\
1-p & 0 & p & \dots & 0 \\
0 & 1-p & 0 & \dots & p \\
\vdots & \vdots & \ddots & \ddots & \vdots \\
0 & \dots & 0 & 1-p & p \\
0 & \dots & 0 & 1-p & p
\end{bmatrix}.
$$

*Propriedades da Matriz de Transição*: **Estocasticidade**, **Simetria (para $p=1/2$)**, **Sparsa** , **Aperiodicidade**, **Irredutibilidade**, **Estacionaridade**

Como estamos trabalhando com passeio aleatório simétrico, temos $p = \frac{1}{2}$. Temos simetria pois as probabilidades de transição para frente $(i + 1)$ e para trás $(i - 1)$ são iguais!
Consequentemente, temos para assimétrico $p \neq \frac{1}{2}$.

Podemos analisar as matrizes dada a simetria e assímetria associadas e suas propriedades!

####  Exemplo para \( N = 3 \) (espaço \( S = \{0, 1, 2, 3\} \))

Com \( p = 0.5 \) e contornos reflexivos:
$$
P =
\begin{bmatrix}
0.5 & 0.5 & 0 & 0 \\
0.5 & 0 & 0.5 & 0 \\
0 & 0.5 & 0 & 0.5 \\
0 & 0 & 0.5 & 0.5
\end{bmatrix}.
$$
*Propriedades Específicas*: **Recorrência**, **Distribuição Assintótica**

#### Caso passeio Aleatório Assimétrico $p \neq \frac{1}{2}$

Com \( p = 0.66 \) e contornos reflexivos:
$$
P =
\begin{bmatrix}
0.33 & 0.66 & 0 & 0 \\
0.33 & 0 & 0.66 & 0 \\
0 & 0.33 & 0 & 0.66 \\
0 & 0 & 0.33 & 0.66
\end{bmatrix}.
$$
*Propriedades Específicas*: **Têndencia Direcional**, **Irreversibilidade**

### Exemplos de transição a **n** passos:

É interessante observar o comportamento da matriz de transição para um número grande de passos. Vamos considerar o caso de  $N = 3$  e  $p = 0.5$  e calcular a matriz de transição para $n = 2$ e $n = 3$, $n=4$ e $n=500$.

Matriz $P^2$ (transição em 2 passos):

$$
P^2 =
\begin{bmatrix}
0.5 & 0.25 & 0.25 & 0 \\
0.25 & 0.5 & 0 & 0.25 \\
0.25 & 0 & 0.5 & 0.25 \\
0 & 0.25 & 0.25 & 0.5
\end{bmatrix}.
$$

O que podemos observar aqui?

- As probabilidades de transição são mais equilibradas em relação à matriz original $P$, pois a random walk ja teve chance de "se mover" por mais de um passo.
- Apesar de se espalhar o sistema ainda não atingiu uma distribuição homogênea. A cadeia ainda possui alguma "memória" do estado inicial.
- O sistema começa a ter uma chance maior de ir para estados não-adjacentes, mas ainda há certa "preferência" por estados adjacentes.

Matriz $P^3$ (transição em 3 passos):

$$
P^3 =
\begin{bmatrix}
0.375 & 0.375 & 0.125 & 0.125 \\
0.375 & 0.125 & 0.375 & 0.125 \\
0.125 & 0.375 & 0.125 & 0.375 \\
0.125 & 0.125 & 0.375 & 0.375
\end{bmatrix}.
$$

O que podemos observar aqui?

- As probabilidades estão mais equilibradas entre os estados.
- Apesar de ainda não ser completamente uniforme, da para notar uma maior "mistura" entre os estados.
- O sistema está começando a perder memória do seu estado inicial, a cadeia está mais "descentralizada" e as probabilidades começam a se espalhar mais uniformemente.

Matriz $P^4$ (transição em 4 passos):

$$
P^4 =
\begin{bmatrix}
0.375 & 0.25 & 0.25 & 0.125 \\
0.25 & 0.375 & 0.125 & 0.25 \\
0.25 & 0.125 & 0.375 & 0.25 \\
0.125 & 0.25 & 0.25 & 0.375
\end{bmatrix}.
$$

O que podemos observar aqui?

- Após 4 passos, as probabilidades de transição entre os estados estão quase equilibradas, com uma leve tendência para os estados vizinhos
- O sistema parece estar alcançando um comportamento de **distribuição estacionárioa** (ou próxima disso pelo menos)
- Esse é um comportamento típico de uma cadeia de Markov que está perdendo sua "memória" do estado inicial e se aproximando de uma distribuição a longo prazo

Matriz $P^{500}$ (transição em 500 passos):

$$
P^{500} =
\begin{bmatrix}
0.25 & 0.25 & 0.25 & 0.25 \\
0.25 & 0.25 & 0.25 & 0.25 \\
0.25 & 0.25 & 0.25 & 0.25 \\
0.25 & 0.25 & 0.25 & 0.25
\end{bmatrix}.
$$


O que podemos observar aqui?

- A matriz $P^{500}$ nos mostra que, após um grande número de passos as probabilidades de transição entre os estados estão completamente equilibradas e uniformes
- Cada estado tem uma probabilidade de transitar para qualquer outro estado. Portanto depois de muitos passos a cadeia de Markov perde sua memória do estado inicial e atinge um estado de **equilíbrio estacionário**
- Essa distribuição uniforme de probabilidades é característica de uma cadeia de Markov irreducível e aperiódica, onde todos os estados são acessíveis e a cadeia não possui ciclos regulares.
  


## Distribuições (invariante e limite)
### Distribuição invariante
A **distribuição invariante** de uma cadeia de Markov como vista em aula é uma distribuição de probabilidade $\pi = (\pi_i)$ tal que, ao aplicarmos a matriz de transição $P$, a distribuição permanece inalterada tal que:
$$
\pi P = \pi.
$$

Em nosso contexto de apresentação (passeio aleatório simétrico *reflexivo*) a "particula" pode explorar todo o espaço $S = \{0,1,...,N\}$ de forma contínuam retornando os estados após atingir os extremos.

Nesse caso então a distribuição invariante neste caso será **uniforme** (pois note que o passeio é simétrico).

Se $\pi = [\pi_0, \pi_1, \dots, \pi_N]$ representa a distribuição invariante:

então

$$
\pi_i = \frac{1}{N+1}, \quad \forall i \in \{0, 1, \dots, N\}.
$$

Note que a distribuição reflete o fato de que ao longo prazo todos os estados têm a mesma probabilidade de serem visitados como confirmamos com as matrizes de transição acima.


**Para o nosso exemplo de espaço discreto finito $S={0, 1, 2,3}:$**
$$
P = \begin{bmatrix}
\frac{1}{2} & \frac{1}{2} & 0 & 0 \\
\frac{1}{2} & 0 & \frac{1}{2} & 0 \\
0 & \frac{1}{2} & 0 & \frac{1}{2} \\
0 & 0 & \frac{1}{2} & \frac{1}{2}
\end{bmatrix} \
$$

A distribuição invariante será:

$$
\pi = \left( \frac{1}{4}, \frac{1}{4}, \frac{1}{4}, \frac{1}{4} \right)
$$

vc
*Ao longo prazo a partícula estará em qualquer estado com a mesma probabilidade*

### Distribuição Limite
A **distibuição limite** de uma cadeia de Markov é o estado ao qual a distribuição converge  muitas iterações da matriz da transição, isto é, quando $n \to \infty$ independente da distribuição inicial $\pi^{(0)}$

$$
\lim_{n \to \infty} P^n(i, j)
$$

Como vimos em aula, um **espaço de estados finitos**, a distribuição limite será igual à distribuição invariante.

Tendo isso em mente, no nosso caso reflexivo a **distribuição limite** coincide com a distribuição invariante:

$$
\lim_{t \to \infty} P(X_t = i) = \pi_i = \frac{1}{N+1}, \quad \forall i.
$$

Isso acontece por que o controno reflexivo permite que o sistema continue a se misturar e alcançar equilíbrio uniforme.

Temos com isso algumas propriedades importantes para esse tipo de random walk:

- **Reversibilidade** : O passeio com contorno reflexivo é reversível, ou seja temos equilbrio de probabilidade tal que:

$$
\pi_i P_{ij} = \pi_j P_{ji}, \quad \forall i, j.
$$

- **Mixing Time**: O tempo necessário para atingir a distribuição uniforme (limite) depende do tamanho do espaçço $N + 1$
- **Propriedade de Confinamento** : O reflexivo evita que a partícula "escape", garantindo que a soma das probabilidades seja sempre 1.
  
**Muda muita coisa se estamos falando de contorno absorvente?** *Muda sim, e muito!*

Se analisarmos o contexto do passeio aleatório simétrico com **contorno absorvente**, vemos que as regras de transições são modificadas, de modo que, ao atingir um dos estados do contorno ($i=0$ ou $i=N$), o processo **não pode mais sair desse estado**.

Então ao vermos a **distribuição estacionária**, temos que ver diferente do sentido clássico pois o sistema pode ser absorvido em $0$ ou $N$. No entando podemos descrever a **probabilidade de absorção** em cada estado absorvente. 

Então suponhamos que o passeio comece no estado $i (1 \leq i \leq N-1)$. 

- $P^{(0)}_i$ -> Probabiliadde do passeio ser absorvido no estado 0
- $P^{(N)}_i$ -> Probabiliadde do passeio ser absorvido no estado N

Isso pode ser modelado pelas equações de **probabilidades de absorção.**

As equações de recorrência de $P^{(0)}_i$ e $P^{(N)}_i$ são dadas por:

$$
P^{0}_i = \frac{1}{2} P_{i-1}^{(0)} + \frac{1}{2} P_{i+1}^{(0)}
$$

com as condições de contorno:

$$
P_0^{(0)} = 1, \quad P_N^{(0)} = 0.
$$


fica análogo a probabilidade de absorção em $N$:

$$
P_i^{(N)} = \frac{1}{2} P_{i-1}^{(N)} + \frac{1}{2} P_{i+1}^{(N)}
$$

com as condições de contorno:

$$
P_0^{(N)} = 0, \quad P_N^{(N)} = 1.
$$

Essas equações resolvidas de forma analítica resultam em soluções que descrevem a probabilidade de absorção de qualquer estado $i$.

Para um $P^{0}_i$ (probabilidade de ser absorvido no estado 0)

$$
P_i^{(0)} = \frac{N - i}{N}.
$$

Para um $P^{N}_i$ (probabilidade de ser absorvido no estado N)

$$
P_i^{(N)} = \frac{i}{N}.
$$

Quando falamos agora da **distribuição limite** falamos do passeio ser absorvido em um dos estados de contorno, dessa forma o processo termina.
Então a distribução limite estará concentrada nas **probabilidades de absorção $0$ e $N$**

E as probabilidades são as mesmas dadas acima para $P^{0}_i$ e $P^{N}_i$.

Essas probabilidades determinam a **distribuição limite** do processo quando o número de passos tende para o infinito, pois o processo se estabiliza no estado absorvente após um nímero suficiente de transições.

## Classificação dos estados e da cadeia;

Por definição um estado $i$ é dito ser **recorrente** se $v_{ii}^*=1$ (a cadeira retorna ao $i$ com probabilidade 1).

O estado $i$ é dito ser transiente se ele não é recorrente.

Portanto, para a matriz de exemplo, considerando $p=\frac{1}{2}$:

$$
P =
\begin{bmatrix}
\frac{1}{2} & \frac{1}{2} & 0 & 0 & 0 \\
\frac{1}{2} & 0 & \frac{1}{2} & 0 & 0 \\
0 & \frac{1}{2} & 0 & \frac{1}{2} & 0 \\
0 & 0 & \frac{1}{2} & 0 & \frac{1}{2} \\
0 & 0 & 0 & \frac{1}{2} & \frac{1}{2}
\end{bmatrix}.
$$

<div style="text-align: center;">
![](img\01.png)
</div>

Análisando o grafo podemos notar que os estados {0,1,2,3,4} são uma classe fechada, irredutível.

George Pólya, em 1921, provou o teorema denominado "Teorema de Pólya" ou "Teorema da Recorrência de Caminhadas Aleatórias":

*"Um passeio aleatório simples em $\mathbb{Z}^D$ é recorrente se e somente se é simétrico e D < 3."*

Então, temos a distribuição estacionária:

$$
\pi_{i}=\frac{1}{2}\pi_{i-1}+\frac{1}{2}\pi_{i}
$$
Por exemplo:

$$
\pi_{2}=\frac{1}{2}\pi_{1}+\frac{1}{2}\pi_{2}\implies \pi_{1}=\pi_{2}
$$
Podemos mostrar que:
$$
\pi_{0}=\pi_{1}=\pi_{2}=\pi_{3}=\pi_{4}
$$
Usando a condição de normalização para essa distribuição estacionária:
$$
\pi_{0}+\pi_{1}+\pi_{2}+\pi_{3}+\pi_{4}=1
$$
Portanto
$$
\pi = (\frac{1}{5},\frac{1}{5},\frac{1}{5},\frac{1}{5},\frac{1}{5})
$$
A soma das probabilidades para deslocamento a esquerda e a direita são iguais, então podemos argumentar que a distribuição estacionária é constante para todos os estados.

Assim temos, para todos os estados $i$:

$$
\pi_{i}=\pi_{0}
$$

Como temos um processo recorrente e com distribuição estacionária $\pi_{i}=\pi_{0}$ concluímos que todos os estados em um processo de caminhada aleatória simétrica de dimensão 2 são recorrentes nulos.

Ou seja, embora o processo seja recorrente, o tempo médio para retornar ao estado inicial (ou qualquer estado específico) é infinito. O processo eventualmente retorna ao estado, mas o tempo médio de retorno é infinito.

O mesmo foi provado por George Pólya: "Em dimensões $d=2$, a caminhada aleatória simétrica é recorrente, mas o tempo médio de retorno ao ponto de origem é infinito, o que caracteriza uma recorrência nula."

## Periodicidade;
 O estado $i$ tem período d se $P_{i,i}^n = 0$ sempre que $n$ não for divisível por $d$, e $d$ é o maior inteiro com essa propriedade. Por exemplo, começando no estado $i$ só sera possível o processo acessar o estado $i$ nos tempo 2,4,6,8,..., nesse caso o estado $i$ tem período 2. Um estado com período 1 é classificado como **aperiódico**. Periodicidade é uma propriedade de classe, ou seja, se o estado $i$ tem período $d$, e o estado $i$ e $j$ se comunicam, então o estado $j$ também tem período $d$.

 *Referência: Sheldon, M. Ross: Introduction to probability models"

### Random Walk simétrica infinita com D = 1 e D = 2:
 Em ambas as dimensões \(D = 1\) e \(D = 2\), o passeio aleatório simétrico é \textbf{recorrente}, ou seja, com \textbf{probabilidade 1}, o caminhante retornará à origem após um número finito de passos. Além disso, como todos os estados são \textbf{comunicáveis} entre si, isso implica que todos os estados terão o mesmo período, conforme a definição de \textbf{periodicidade}. O raciocínio para entender a periodicidade de um passeio aleatório simétrico em \(D = 1\) e \(D = 2\) é análogo, com o mesmo princípio fundamental de que o retorno à origem só ocorre após um número \textbf{par} de passos.
 Para retornar ao estado zero, é necessário que o caminhante dê \(n\) passos em uma direção e \(n\) passos na direção oposta (para a direita e para a esquerda, no caso de \(D = 1\), ou em direções horizontais e verticais, no caso de \(D = 2\)). Dessa forma, o retorno à origem só é possível após \(2n\) passos. Como o retorno ao estado zero ocorre apenas em \textbf{tempos pares}, podemos definir o passeio aleatório como tendo \textbf{período \(d = 2\)}.
 
 Exemplo do tempo de recorrencia ao estado zero de um random walk D = 1:
 ```{r}
 library(ggplot2)

 simular_passeio_aleatorio <- function(n_passos) {
  passos <- sample(c(-1, 1), size = n_passos, replace = TRUE)
  trajetoria <- cumsum(passos)
  tempos_zero <- which(trajetoria == 0)
  return(list(trajetoria = trajetoria, tempos_zero = tempos_zero))
 }

 n_passos <- 100
 resultado <- simular_passeio_aleatorio(n_passos)

 df <- data.frame(Passo = 1:n_passos, Posição = resultado$trajetoria)
 df_zero <- data.frame(Passo = resultado$tempos_zero, Posição = rep(0, length(resultado$tempos_zero)))

 df_legenda <- data.frame(Passo = resultado$tempos_zero)

 ggplot(df, aes(x = Passo, y = Posição)) +
  geom_line(color = "blue", size = 1) +
  geom_point(data = df_zero, aes(x = Passo, y = Posição), color = "red", size = 3) +
  geom_hline(yintercept = 0, color = "black", linetype = "dashed", size = 0.8) +
  labs(x = "t", y = "X(t)") +
  theme_minimal() +
  theme(axis.text = element_text(size = 5), axis.title = element_text(size = 14)) +
  annotate("text", x = max(df$Passo) * 0.8, y = max(df$Posição) * 0.9, 
           label = paste("Índices de Recorrência ao Zero:\n", paste(df_legenda$Passo, collapse = ", ")), 
           size = 4, hjust = 1)

 ```

 Podemos perceber que todos os períodos em que o processo retorna ao zero são pares.

### Random Walk simétrica com \(D \geq 3\):
Em dimensões \(D \geq 3\), o comportamento do passeio aleatório simétrico difere significativamente daquele observado em \(D = 1\) e \(D = 2\). Nesses casos, o passeio aleatório se torna \textbf{transiente}, o que significa que, com \textbf{probabilidade 1}, o caminheiro não retornará à origem após um número finito de passos.

Além disso, em dimensões \(D \geq 3\), o passeio aleatório é \textbf{aperiódico}, o que significa que não existe um período fixo \(d\) tal que o caminheiro retorne à origem após múltiplos inteiros de \(d\) passos.


## Tempo de 1° visita/passagem e recorrência ???

## Probabilidade de Absorção ???

## Curiosidades ???

## Exercícios

1. Considere um passeio aleatório simétrico ($p = 0.5$) Dado que $X_0 = 0$, encontre a probabilidade de retorno em $t = 2n$, ou seja, $P(X_{2n} = 0)$.

Para retornar a um estado precisamos que o número de passos a direita seja igual ao número de passos a esquerda.

Portanto a probabilidade de **um caminho** de retorno seria;
$$
p^n(1-p)^n
$$
Se tratando de um passeio aleatório simétrico essa expressão é equivalente a;
$$
(0.5)^n(0.5)^n = (0.5)^{2n}
$$

Para chegar a probabilidade precisamos multiplicar pelo número de sequências (combinações de passos) que satisfazem a condição de termos o mesmo número passos para cada lado:
$$
\binom{2n}{n} = \frac{2n!}{n!(2n-n)!}
$$

Portanto;
$$
P(X_{2n} = 0) = \binom{2n}{n}(0.5)^{2n}
$$

Note ainda que como $t$ é uma contagem do número de passos e consideramos apenas passos completos temos que $t \in \mathbb{N}$.

Logo para **t ímpar** a combinação não está definida, assim;
$$
P(X_{2n} = 0) = \binom{t}{\frac{t}{2}}p^{\frac{t}{2}}(1-p)^{\frac{t}{2}} = 0
$$
Concluímos com isso que é impossível voltar ao mesmo estado com um número ímpar de passos.

2. Usando R, simule e plote um passeio aleatório simétrico em uma dimensão com $n$ passos depois responda:
a) Houveram quantos retornos à origem? Qual foi a distância máxima da origem?
b) Repita a simulação $N$ vezes. Considere $F$ como a posição final do passeio, plote a distribuição de $F$.
c) Considerando a simulação do item anterior, qual foi o tempo médio de 1° retorno à origem?

```{r ex2}

sim_random_walk <- function(n) {

    steps <- sample(c(-1, 1), size = n, replace = TRUE, prob = c(.5, .5))
    return(cumsum(steps))
}

n_steps <- 1000
n_rep   <- 100

first_walk <- sim_random_walk(n_steps)
df         <- data.frame(step = 1:n_steps, position = first_walk)

ggplot(df, aes(x = step, y = position)) +
    geom_line() +
    labs(title = "simulação de 1 passeio aleatório",
       x     = "Passo",
       y     = "Posição") +
    theme_minimal()
```

Contando retornos ao ponto de origem, no caso $X_0 = 0$ e a distância máxima do ponto inicial;

```{r ex2a}

returns_to_0 <- sum(first_walk == 0)
max_dist     <- max(abs(first_walk))

cat("Número de retornos à origem: ", returns_to_0, "\n")
cat("Distância máxima alcançada do ponto inicial: ", max_dist, "\n")
```

Passo em que ocorreu a primeira volta a origem;

```{r}

first_return <- min(which(first_walk == 0))

if (is.finite(first_return)) {
    first_return
} else {
    cat("Não houve retorno.\n")
}
```

Distribuição da posição final considerando `r n_rep` repetições;

```{r ex2b}

all_walks    <- list()
return_times <- c()

for (i in 1:n_rep){

    all_walks[[i]]  <- sim_random_walk(n_steps)

    if (is.finite(min(which(all_walks[[i]][-1] == 0)))) {
        return_times[i] <- min(which(all_walks[[i]][-1] == 0))
    } else {
        return_times[i] <- 0
    }
}

df <- data.frame(step = rep(1:n_steps, times = n_rep),
                 position = unlist(all_walks),
                 walk = rep(1:n_rep, each = n_steps))

ggplot(df, aes(x = step, y = position, group = walk, color = as.factor(walk))) +
    geom_line(alpha = 0.7) +
    labs(title = "Trajetórias Simuladas",
         x = "Passo",
         y = "Posição",
         color = "Passeio") +
    theme_minimal() +
    theme(legend.position = "none")

df <- data.frame(final_pos = sapply(all_walks, function(walk) tail(walk, 1)))

ggplot(df, aes(x = final_pos)) +
    geom_histogram(fill = "lightblue", alpha = 0.7) +
    labs(title = "Distribuição da posição final",
         x     = "F",
         y     = "") +
    theme_minimal()
```

Estatísticas de 1° retorno ao ponto inicial:

```{r, echo = FALSE}

cat("Média do tempo de retorno:", mean(return_times[return_times > 0]), "passos.\n")

df <- data.frame(returns = return_times[return_times > 0])

ggplot(df, aes(x = returns)) +
    geom_histogram(fill = "lightgreen", alpha = 0.7) +
    labs(title = "Distribuição número de passos até o retorno",
         x = "Passos",
         y = "Frequência") +
    scale_x_continuous(limits = c(0,75)) +
    scale_y_continuous(limits = c(0,200)) +
    theme_minimal()

cat(sum(return_times == 0), "caminhos não retornaram ao estado zero.\n")
cat("Isso representa", sum(return_times == 0)/n_rep, "do total de simulações.\n")
```
